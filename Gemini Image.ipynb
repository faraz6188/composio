{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8816bc3-ba52-4520-aaab-1019504e1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/Seven Men In Dark Suits Around Elegant Dinner Table.png\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatSession' object has no attribute 'send_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Check if the input is an image path\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(user_input) \u001b[38;5;129;01mand\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# If it's an image, process it and send it to the model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_image\u001b[49m(user_input)  \u001b[38;5;66;03m# Assuming send_image is a method that handles image inputs\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mtext})\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# If it's a text message, process it as usual\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatSession' object has no attribute 'send_image'"
     ]
    }
   ],
   "source": [
    "import os  # For handling file paths\n",
    "import google.generativeai as genai # imports the google.generativeai module and assigns it to the name genai\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start with an empty history list to store conversation\n",
    "history = []\n",
    "\n",
    "# Initialize the chat session\n",
    "chat = model.start_chat(history=history)\n",
    "\n",
    "while True:\n",
    "    # Get user input or image path\n",
    "    user_input = input(\"Enter your message or image path (or type 'exit' to stop): \")\n",
    "\n",
    "    # Break loop if the user wants to exit\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Check if the input is an image path\n",
    "    if os.path.isfile(user_input) and user_input.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        # If it's an image, process it and send it to the model\n",
    "        response = chat.send_image(user_input)  # Assuming send_image is a method that handles image inputs\n",
    "        history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "    else:\n",
    "        # If it's a text message, process it as usual\n",
    "        history.append({\"role\": \"user\", \"parts\": user_input})\n",
    "        \n",
    "        # Send the user's message to the chat and get the response\n",
    "        response = chat.send_message(user_input)\n",
    "        \n",
    "        # Append the model's response to the history\n",
    "        history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"Model: {response.text}\")\n",
    "\n",
    "# Optional: Save conversation history to a file for later reference\n",
    "with open(\"chat_history.txt\", \"w\") as f:\n",
    "    for entry in history:\n",
    "        f.write(f\"{entry['role']}: {entry['parts']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788e8ee2-b509-4552-88d9-27f13366d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/Create a digita a3f08c05-ed44-4738-8ef8-46947a8d5d7a.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n",
      "Extracted Text: \n",
      "No valid content found in the image.\n",
      "Model: Please provide me with the image you would like me to describe. I need the image itself or a link to it in order to understand and explain it. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  Explain image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Please provide me with the image you would like me to describe. You can either:\n",
      "\n",
      "* **Upload the image:**  You can upload the image directly to me if you are using a platform that allows file uploads.\n",
      "* **Provide a URL:**  If the image is hosted online, you can provide me with the URL.\n",
      "* **Describe the image:** If you can't share the image itself, you can give me a detailed description of it, including things like:\n",
      "    * What is the subject of the image? (people, objects, landscapes, etc.)\n",
      "    * What colors are present?\n",
      "    * What is the overall mood or feeling of the image?\n",
      "    * Are there any significant details or features?\n",
      "\n",
      "Once I have the image or description, I can try my best to provide you with an accurate description. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  who is person on image ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Please provide me with the image so I can identify the person. I need to see the image to be able to tell you who it is. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/IMG_4994.PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n",
      "Extracted Text: \n",
      "No valid content found in the image.\n",
      "Model: Please provide me with the image so I can identify the person. I need to see the image to be able to tell you who it is. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  what is going on in the image ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Please provide me with the image so I can tell you what is going on! I need to see it to understand the context.  \n",
      "\n",
      "Let me know if you can upload the image or provide a link to it. ðŸ˜Š \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  exit\n"
     ]
    }
   ],
   "source": [
    "import os  # For handling file paths\n",
    "from PIL import Image  # For image processing\n",
    "import pytesseract  # For OCR (Optical Character Recognition) if needed\n",
    "\n",
    "# Initialize the model\n",
    "genai.configure(api_key=\"AIzaSyCTtah3iahaJ6-TirG8Zapn_KE6sqSwamc\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start with an empty history list to store conversation\n",
    "history = []\n",
    "\n",
    "# Initialize the chat session\n",
    "chat = model.start_chat(history=history)\n",
    "\n",
    "while True:\n",
    "    # Get user input or image path\n",
    "    user_input = input(\"Enter your message or image path (or type 'exit' to stop): \")\n",
    "\n",
    "    # Break loop if the user wants to exit\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Check if the input is an image path\n",
    "    if os.path.isfile(user_input) and user_input.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        try:\n",
    "            # Open and process the image\n",
    "            img = Image.open(user_input)\n",
    "            print(\"Image loaded successfully.\")\n",
    "\n",
    "            # Extract text from image using OCR\n",
    "            text_from_image = pytesseract.image_to_string(img)\n",
    "            print(f\"Extracted Text: {text_from_image}\")\n",
    "\n",
    "            if text_from_image.strip():  # Check if there's valid text\n",
    "                response = chat.send_message(text_from_image)\n",
    "                history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "            else:\n",
    "                print(\"No valid content found in the image.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")  # This handles any errors during image processing\n",
    "    else:\n",
    "        # If it's a text message, process it as usual\n",
    "        history.append({\"role\": \"user\", \"parts\": user_input})\n",
    "        \n",
    "        # Send the user's message to the chat and get the response\n",
    "        try:\n",
    "            response = chat.send_message(user_input)\n",
    "            history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending message: {e}\")  # Handle errors when sending messages\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"Model: {response.text}\")\n",
    "\n",
    "# Optional: Save conversation history to a file for later reference\n",
    "with open(\"chat_history.txt\", \"w\") as f:\n",
    "    for entry in history:\n",
    "        f.write(f\"{entry['role']}: {entry['parts']}\\n\")\n",
    "            \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878ae831-610e-4d14-bf5c-5d16c3d67f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytesseract) (10.4.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303c3c0c-6242-41b0-bc41-9948aecaa811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/Create a digita a3f08c05-ed44-4738-8ef8-46947a8d5d7a.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n",
      "Extracted Text: \n",
      "No valid content found in the image.\n",
      "Model: Please provide me with the image so I can tell you what is going on! I need to see it to understand the context.  \n",
      "\n",
      "Let me know if you can upload the image or provide a link to it. ðŸ˜Š \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  exit\n"
     ]
    }
   ],
   "source": [
    "import os  # For handling file paths\n",
    "from PIL import Image  # For image processing\n",
    "import pytesseract  # For OCR (Optical Character Recognition) if needed\n",
    "\n",
    "# Initialize the model\n",
    "genai.configure(api_key=\"AIzaSyCTtah3iahaJ6-TirG8Zapn_KE6sqSwamc\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start with an empty history list to store conversation\n",
    "history = []\n",
    "\n",
    "# Initialize the chat session\n",
    "chat = model.start_chat(history=history)\n",
    "\n",
    "while True:\n",
    "    # Get user input or image path\n",
    "    user_input = input(\"Enter your message or image path (or type 'exit' to stop): \")\n",
    "\n",
    "    # Break loop if the user wants to exit\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Check if the input is an image path\n",
    "    if os.path.isfile(user_input) and user_input.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        try:\n",
    "            # Open and process the image\n",
    "            img = Image.open(user_input)\n",
    "            print(\"Image loaded successfully.\")\n",
    "\n",
    "            # Extract text from image using OCR\n",
    "            text_from_image = pytesseract.image_to_string(img)\n",
    "            print(f\"Extracted Text: {text_from_image}\")\n",
    "\n",
    "            if text_from_image.strip():  # Check if there's valid text\n",
    "                response = chat.send_message(text_from_image)\n",
    "                history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "            else:\n",
    "                print(\"No valid content found in the image.\")\n",
    "            \n",
    "            # Save the uploaded image path in history\n",
    "            history.append({\"role\": \"user\", \"parts\": f\"Uploaded Image: {user_input}\"})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")  # This handles any errors during image processing\n",
    "    else:\n",
    "        # If it's a text message, process it as usual\n",
    "        history.append({\"role\": \"user\", \"parts\": user_input})\n",
    "        \n",
    "        # Send the user's message to the chat and get the response\n",
    "        try:\n",
    "            response = chat.send_message(user_input)\n",
    "            history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending message: {e}\")  # Handle errors when sending messages\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"Model: {response.text}\")\n",
    "\n",
    "# Optional: Save conversation history to a file for later reference\n",
    "with open(\"chat_history.txt\", \"w\") as f:\n",
    "    for entry in history:\n",
    "        f.write(f\"{entry['role']}: {entry['parts']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdeccdfe-d65c-410b-910a-57ad5690bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/bb.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and preprocessed successfully.\n",
      "Extracted Text: ''\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError sending message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Handle errors when sending messages\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresponse\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Optional: Save conversation history to a file for later reference\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pytesseract  # For OCR (Optical Character Recognition)\n",
    "import cv2  # OpenCV for image processing\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCTtah3iahaJ6-TirG8Zapn_KE6sqSwamc\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start with an empty history list to store conversation\n",
    "history = []\n",
    "\n",
    "# Initialize the chat session\n",
    "chat = model.start_chat(history=history)\n",
    "\n",
    "while True:\n",
    "    # Get user input or image path\n",
    "    user_input = input(\"Enter your message or image path (or type 'exit' to stop): \")\n",
    "\n",
    "    # Break loop if the user wants to exit\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Check if the input is an image path\n",
    "    if os.path.isfile(user_input) and user_input.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        try:\n",
    "            # Open and preprocess the image using OpenCV\n",
    "            img = cv2.imread(user_input)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "            _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)  # Apply thresholding\n",
    "            \n",
    "            print(\"Image loaded and preprocessed successfully.\")\n",
    "\n",
    "            # Extract text from image using OCR\n",
    "            text_from_image = pytesseract.image_to_string(thresh)\n",
    "            print(f\"Extracted Text: '{text_from_image}'\")\n",
    "            \n",
    "            # Save the uploaded image path in history\n",
    "            history.append({\"role\": \"user\", \"parts\": f\"Uploaded Image: {user_input}\"})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")  # This handles any errors during image processing\n",
    "    else:\n",
    "        # If it's a text message, process it as usual\n",
    "        history.append({\"role\": \"user\", \"parts\": user_input})\n",
    "        \n",
    "        # Send the user's message to the chat and get the response\n",
    "        try:\n",
    "            response = chat.send_image(user_input)\n",
    "            history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending message: {e}\")  # Handle errors when sending messages\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"Model: {response.text}\")\n",
    "\n",
    "# Optional: Save conversation history to a file for later reference\n",
    "with open(\"chat_history.txt\", \"w\") as f:\n",
    "    for entry in history:\n",
    "        f.write(f\"{entry['role']}: {entry['parts']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9135636-749b-4637-b9cd-57b298517805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/bb.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and preprocessed successfully.\n",
      "Extracted Text: ''\n",
      "No valid content found in the image.\n",
      "Model: Please provide me with the image so I can tell you what is going on! I need to see it to understand the context.  \n",
      "\n",
      "Let me know if you can upload the image or provide a link to it. ðŸ˜Š \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  exit\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2328546-4572-4269-8271-3e226afed241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message or image path (or type 'exit' to stop):  /Users/mdfarazali/Downloads/bb.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and preprocessed successfully.\n",
      "Extracted Text: ''\n",
      "No valid content found in the image.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pytesseract  # For OCR (Optical Character Recognition)\n",
    "import cv2  # OpenCV for image processing\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCTtah3iahaJ6-TirG8Zapn_KE6sqSwamc\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "history = []\n",
    "chat = model.start_chat(history=history)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter your message or image path (or type 'exit' to stop): \")\n",
    "\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Check if the input is an image path\n",
    "    if os.path.isfile(user_input) and user_input.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        try:\n",
    "            # Open and preprocess the image using OpenCV\n",
    "            img = cv2.imread(user_input)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            print(\"Image loaded and preprocessed successfully.\")\n",
    "\n",
    "            # Extract text from image using OCR\n",
    "            text_from_image = pytesseract.image_to_string(thresh)\n",
    "            print(f\"Extracted Text: '{text_from_image}'\")\n",
    "\n",
    "            if text_from_image.strip():  # If text is extracted, send it to the model\n",
    "                response = chat.send_message(text_from_image)\n",
    "                history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "            else:\n",
    "                print(\"No valid content found in the image.\")\n",
    "                response = None\n",
    "\n",
    "            # Save the uploaded image path in history\n",
    "            history.append({\"role\": \"user\", \"parts\": f\"Uploaded Image: {user_input}\"})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")\n",
    "            response = None\n",
    "    else:\n",
    "        # If it's a text message, process it as usual\n",
    "        history.append({\"role\": \"user\", \"parts\": user_input})\n",
    "\n",
    "        try:\n",
    "            response = chat.send_message(user_input)\n",
    "            history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending message: {e}\")\n",
    "            response = None\n",
    "\n",
    "    # Print the response only if it exists\n",
    "    if response:\n",
    "        print(f\"Model: {response.text}\")\n",
    "\n",
    "# Optional: Save conversation history to a file for later reference\n",
    "with open(\"chat_history.txt\", \"w\") as f:\n",
    "    for entry in history:\n",
    "        f.write(f\"{entry['role']}: {entry['parts']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4756ab7-ffe7-494b-8cb3-0f06e310a9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
